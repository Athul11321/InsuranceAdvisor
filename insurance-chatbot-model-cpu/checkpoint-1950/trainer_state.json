{
  "best_global_step": 1800,
  "best_metric": 2.0070605278015137,
  "best_model_checkpoint": "./insurance-chatbot-model-cpu\\checkpoint-1800",
  "epoch": 1.0,
  "eval_steps": 100,
  "global_step": 1950,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005128205128205128,
      "grad_norm": 0.8874980807304382,
      "learning_rate": 9e-06,
      "loss": 15.0994,
      "step": 10
    },
    {
      "epoch": 0.010256410256410256,
      "grad_norm": 0.904498279094696,
      "learning_rate": 1.9e-05,
      "loss": 15.3935,
      "step": 20
    },
    {
      "epoch": 0.015384615384615385,
      "grad_norm": 1.0757416486740112,
      "learning_rate": 2.9e-05,
      "loss": 15.079,
      "step": 30
    },
    {
      "epoch": 0.020512820512820513,
      "grad_norm": 1.22202730178833,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 15.2765,
      "step": 40
    },
    {
      "epoch": 0.02564102564102564,
      "grad_norm": 1.6683682203292847,
      "learning_rate": 4.9e-05,
      "loss": 15.2948,
      "step": 50
    },
    {
      "epoch": 0.03076923076923077,
      "grad_norm": 1.9729818105697632,
      "learning_rate": 4.976315789473685e-05,
      "loss": 15.0152,
      "step": 60
    },
    {
      "epoch": 0.035897435897435895,
      "grad_norm": 2.6981914043426514,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 15.1248,
      "step": 70
    },
    {
      "epoch": 0.041025641025641026,
      "grad_norm": 3.4253509044647217,
      "learning_rate": 4.923684210526316e-05,
      "loss": 14.5332,
      "step": 80
    },
    {
      "epoch": 0.046153846153846156,
      "grad_norm": 4.746592044830322,
      "learning_rate": 4.897368421052632e-05,
      "loss": 14.2332,
      "step": 90
    },
    {
      "epoch": 0.05128205128205128,
      "grad_norm": 5.583873271942139,
      "learning_rate": 4.871052631578948e-05,
      "loss": 13.8553,
      "step": 100
    },
    {
      "epoch": 0.05128205128205128,
      "eval_loss": 12.553199768066406,
      "eval_runtime": 2466.9869,
      "eval_samples_per_second": 3.162,
      "eval_steps_per_second": 3.162,
      "step": 100
    },
    {
      "epoch": 0.05641025641025641,
      "grad_norm": 7.7052226066589355,
      "learning_rate": 4.8447368421052637e-05,
      "loss": 13.2979,
      "step": 110
    },
    {
      "epoch": 0.06153846153846154,
      "grad_norm": 10.607937812805176,
      "learning_rate": 4.818421052631579e-05,
      "loss": 12.7241,
      "step": 120
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 10.865859031677246,
      "learning_rate": 4.792105263157895e-05,
      "loss": 11.8121,
      "step": 130
    },
    {
      "epoch": 0.07179487179487179,
      "grad_norm": 10.256881713867188,
      "learning_rate": 4.7657894736842106e-05,
      "loss": 10.6954,
      "step": 140
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 7.924457550048828,
      "learning_rate": 4.739473684210526e-05,
      "loss": 9.8337,
      "step": 150
    },
    {
      "epoch": 0.08205128205128205,
      "grad_norm": 6.576706886291504,
      "learning_rate": 4.713157894736842e-05,
      "loss": 9.2884,
      "step": 160
    },
    {
      "epoch": 0.08717948717948718,
      "grad_norm": 5.351390361785889,
      "learning_rate": 4.686842105263158e-05,
      "loss": 8.804,
      "step": 170
    },
    {
      "epoch": 0.09230769230769231,
      "grad_norm": 5.399486541748047,
      "learning_rate": 4.660526315789474e-05,
      "loss": 8.2124,
      "step": 180
    },
    {
      "epoch": 0.09743589743589744,
      "grad_norm": 4.806887626647949,
      "learning_rate": 4.6342105263157895e-05,
      "loss": 7.7663,
      "step": 190
    },
    {
      "epoch": 0.10256410256410256,
      "grad_norm": 4.912354469299316,
      "learning_rate": 4.607894736842105e-05,
      "loss": 7.3277,
      "step": 200
    },
    {
      "epoch": 0.10256410256410256,
      "eval_loss": 6.040970325469971,
      "eval_runtime": 2181.7844,
      "eval_samples_per_second": 3.575,
      "eval_steps_per_second": 3.575,
      "step": 200
    },
    {
      "epoch": 0.1076923076923077,
      "grad_norm": 4.761202812194824,
      "learning_rate": 4.5815789473684215e-05,
      "loss": 6.9405,
      "step": 210
    },
    {
      "epoch": 0.11282051282051282,
      "grad_norm": 3.958347797393799,
      "learning_rate": 4.555263157894737e-05,
      "loss": 6.5884,
      "step": 220
    },
    {
      "epoch": 0.11794871794871795,
      "grad_norm": 4.349133014678955,
      "learning_rate": 4.528947368421053e-05,
      "loss": 6.3328,
      "step": 230
    },
    {
      "epoch": 0.12307692307692308,
      "grad_norm": 3.8133022785186768,
      "learning_rate": 4.502631578947369e-05,
      "loss": 6.0962,
      "step": 240
    },
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 3.4092774391174316,
      "learning_rate": 4.476315789473685e-05,
      "loss": 5.7526,
      "step": 250
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 3.2252635955810547,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 5.5867,
      "step": 260
    },
    {
      "epoch": 0.13846153846153847,
      "grad_norm": 3.0429375171661377,
      "learning_rate": 4.423684210526316e-05,
      "loss": 5.4379,
      "step": 270
    },
    {
      "epoch": 0.14358974358974358,
      "grad_norm": 2.6913466453552246,
      "learning_rate": 4.397368421052632e-05,
      "loss": 5.3012,
      "step": 280
    },
    {
      "epoch": 0.14871794871794872,
      "grad_norm": 3.071636438369751,
      "learning_rate": 4.3710526315789474e-05,
      "loss": 5.1109,
      "step": 290
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 2.9516263008117676,
      "learning_rate": 4.344736842105263e-05,
      "loss": 5.046,
      "step": 300
    },
    {
      "epoch": 0.15384615384615385,
      "eval_loss": 3.99741530418396,
      "eval_runtime": 2179.4073,
      "eval_samples_per_second": 3.579,
      "eval_steps_per_second": 3.579,
      "step": 300
    },
    {
      "epoch": 0.15897435897435896,
      "grad_norm": 2.5870745182037354,
      "learning_rate": 4.3184210526315793e-05,
      "loss": 4.8395,
      "step": 310
    },
    {
      "epoch": 0.1641025641025641,
      "grad_norm": 2.7757351398468018,
      "learning_rate": 4.292105263157895e-05,
      "loss": 4.7307,
      "step": 320
    },
    {
      "epoch": 0.16923076923076924,
      "grad_norm": 3.3007702827453613,
      "learning_rate": 4.2657894736842106e-05,
      "loss": 4.6293,
      "step": 330
    },
    {
      "epoch": 0.17435897435897435,
      "grad_norm": 1.9806405305862427,
      "learning_rate": 4.239473684210526e-05,
      "loss": 4.5011,
      "step": 340
    },
    {
      "epoch": 0.1794871794871795,
      "grad_norm": 3.0680015087127686,
      "learning_rate": 4.213157894736842e-05,
      "loss": 4.4405,
      "step": 350
    },
    {
      "epoch": 0.18461538461538463,
      "grad_norm": 2.1725656986236572,
      "learning_rate": 4.1868421052631576e-05,
      "loss": 4.3469,
      "step": 360
    },
    {
      "epoch": 0.18974358974358974,
      "grad_norm": 2.7430598735809326,
      "learning_rate": 4.160526315789474e-05,
      "loss": 4.2404,
      "step": 370
    },
    {
      "epoch": 0.19487179487179487,
      "grad_norm": 2.771507978439331,
      "learning_rate": 4.1342105263157896e-05,
      "loss": 4.1335,
      "step": 380
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.7776811122894287,
      "learning_rate": 4.107894736842106e-05,
      "loss": 4.0858,
      "step": 390
    },
    {
      "epoch": 0.20512820512820512,
      "grad_norm": 2.2307188510894775,
      "learning_rate": 4.0815789473684215e-05,
      "loss": 3.965,
      "step": 400
    },
    {
      "epoch": 0.20512820512820512,
      "eval_loss": 3.1957499980926514,
      "eval_runtime": 2206.7411,
      "eval_samples_per_second": 3.535,
      "eval_steps_per_second": 3.535,
      "step": 400
    },
    {
      "epoch": 0.21025641025641026,
      "grad_norm": 2.842613458633423,
      "learning_rate": 4.055263157894737e-05,
      "loss": 3.9398,
      "step": 410
    },
    {
      "epoch": 0.2153846153846154,
      "grad_norm": 1.8966431617736816,
      "learning_rate": 4.028947368421053e-05,
      "loss": 3.8739,
      "step": 420
    },
    {
      "epoch": 0.2205128205128205,
      "grad_norm": 2.003436803817749,
      "learning_rate": 4.0026315789473685e-05,
      "loss": 3.8038,
      "step": 430
    },
    {
      "epoch": 0.22564102564102564,
      "grad_norm": 1.7427339553833008,
      "learning_rate": 3.976315789473685e-05,
      "loss": 3.8059,
      "step": 440
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 2.2144439220428467,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 3.7772,
      "step": 450
    },
    {
      "epoch": 0.2358974358974359,
      "grad_norm": 2.4868381023406982,
      "learning_rate": 3.923684210526316e-05,
      "loss": 3.6842,
      "step": 460
    },
    {
      "epoch": 0.24102564102564103,
      "grad_norm": 4.357927322387695,
      "learning_rate": 3.897368421052632e-05,
      "loss": 3.6524,
      "step": 470
    },
    {
      "epoch": 0.24615384615384617,
      "grad_norm": 2.450711965560913,
      "learning_rate": 3.8710526315789474e-05,
      "loss": 3.525,
      "step": 480
    },
    {
      "epoch": 0.2512820512820513,
      "grad_norm": 1.6805593967437744,
      "learning_rate": 3.844736842105263e-05,
      "loss": 3.517,
      "step": 490
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 2.4836223125457764,
      "learning_rate": 3.818421052631579e-05,
      "loss": 3.5263,
      "step": 500
    },
    {
      "epoch": 0.2564102564102564,
      "eval_loss": 2.825998067855835,
      "eval_runtime": 2176.2345,
      "eval_samples_per_second": 3.584,
      "eval_steps_per_second": 3.584,
      "step": 500
    },
    {
      "epoch": 0.26153846153846155,
      "grad_norm": 2.8778693675994873,
      "learning_rate": 3.792105263157895e-05,
      "loss": 3.4913,
      "step": 510
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 2.1201250553131104,
      "learning_rate": 3.765789473684211e-05,
      "loss": 3.4578,
      "step": 520
    },
    {
      "epoch": 0.2717948717948718,
      "grad_norm": 2.83296275138855,
      "learning_rate": 3.739473684210526e-05,
      "loss": 3.3695,
      "step": 530
    },
    {
      "epoch": 0.27692307692307694,
      "grad_norm": 1.7116578817367554,
      "learning_rate": 3.713157894736842e-05,
      "loss": 3.389,
      "step": 540
    },
    {
      "epoch": 0.28205128205128205,
      "grad_norm": 2.113699197769165,
      "learning_rate": 3.686842105263158e-05,
      "loss": 3.274,
      "step": 550
    },
    {
      "epoch": 0.28717948717948716,
      "grad_norm": 1.7071131467819214,
      "learning_rate": 3.660526315789474e-05,
      "loss": 3.3124,
      "step": 560
    },
    {
      "epoch": 0.2923076923076923,
      "grad_norm": 1.577074408531189,
      "learning_rate": 3.6342105263157896e-05,
      "loss": 3.2411,
      "step": 570
    },
    {
      "epoch": 0.29743589743589743,
      "grad_norm": 2.9726321697235107,
      "learning_rate": 3.607894736842106e-05,
      "loss": 3.2178,
      "step": 580
    },
    {
      "epoch": 0.30256410256410254,
      "grad_norm": 2.062549352645874,
      "learning_rate": 3.5815789473684216e-05,
      "loss": 3.183,
      "step": 590
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 1.7566574811935425,
      "learning_rate": 3.555263157894737e-05,
      "loss": 3.1752,
      "step": 600
    },
    {
      "epoch": 0.3076923076923077,
      "eval_loss": 2.6016273498535156,
      "eval_runtime": 2170.3306,
      "eval_samples_per_second": 3.594,
      "eval_steps_per_second": 3.594,
      "step": 600
    },
    {
      "epoch": 0.3128205128205128,
      "grad_norm": 1.8922674655914307,
      "learning_rate": 3.528947368421053e-05,
      "loss": 3.2103,
      "step": 610
    },
    {
      "epoch": 0.31794871794871793,
      "grad_norm": 2.6308627128601074,
      "learning_rate": 3.5026315789473685e-05,
      "loss": 3.1769,
      "step": 620
    },
    {
      "epoch": 0.3230769230769231,
      "grad_norm": 2.478571653366089,
      "learning_rate": 3.476315789473684e-05,
      "loss": 3.0863,
      "step": 630
    },
    {
      "epoch": 0.3282051282051282,
      "grad_norm": 2.679870843887329,
      "learning_rate": 3.45e-05,
      "loss": 3.0634,
      "step": 640
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.550916314125061,
      "learning_rate": 3.423684210526316e-05,
      "loss": 3.0661,
      "step": 650
    },
    {
      "epoch": 0.3384615384615385,
      "grad_norm": 1.5805813074111938,
      "learning_rate": 3.397368421052632e-05,
      "loss": 3.0736,
      "step": 660
    },
    {
      "epoch": 0.3435897435897436,
      "grad_norm": 1.603575348854065,
      "learning_rate": 3.3710526315789475e-05,
      "loss": 2.9971,
      "step": 670
    },
    {
      "epoch": 0.3487179487179487,
      "grad_norm": 1.6577616930007935,
      "learning_rate": 3.344736842105263e-05,
      "loss": 2.9752,
      "step": 680
    },
    {
      "epoch": 0.35384615384615387,
      "grad_norm": 1.7066556215286255,
      "learning_rate": 3.318421052631579e-05,
      "loss": 2.9677,
      "step": 690
    },
    {
      "epoch": 0.358974358974359,
      "grad_norm": 1.647263765335083,
      "learning_rate": 3.2921052631578944e-05,
      "loss": 2.9841,
      "step": 700
    },
    {
      "epoch": 0.358974358974359,
      "eval_loss": 2.4641120433807373,
      "eval_runtime": 2166.0618,
      "eval_samples_per_second": 3.601,
      "eval_steps_per_second": 3.601,
      "step": 700
    },
    {
      "epoch": 0.3641025641025641,
      "grad_norm": 1.4697675704956055,
      "learning_rate": 3.265789473684211e-05,
      "loss": 2.9907,
      "step": 710
    },
    {
      "epoch": 0.36923076923076925,
      "grad_norm": 1.9526004791259766,
      "learning_rate": 3.2394736842105264e-05,
      "loss": 2.9019,
      "step": 720
    },
    {
      "epoch": 0.37435897435897436,
      "grad_norm": 2.5734622478485107,
      "learning_rate": 3.213157894736842e-05,
      "loss": 2.9231,
      "step": 730
    },
    {
      "epoch": 0.37948717948717947,
      "grad_norm": 1.8496532440185547,
      "learning_rate": 3.1868421052631584e-05,
      "loss": 2.8772,
      "step": 740
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.4775713682174683,
      "learning_rate": 3.160526315789474e-05,
      "loss": 2.9096,
      "step": 750
    },
    {
      "epoch": 0.38974358974358975,
      "grad_norm": 1.9755667448043823,
      "learning_rate": 3.1342105263157897e-05,
      "loss": 2.8706,
      "step": 760
    },
    {
      "epoch": 0.39487179487179486,
      "grad_norm": 1.4758328199386597,
      "learning_rate": 3.107894736842105e-05,
      "loss": 2.878,
      "step": 770
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6404304504394531,
      "learning_rate": 3.0815789473684216e-05,
      "loss": 2.8816,
      "step": 780
    },
    {
      "epoch": 0.40512820512820513,
      "grad_norm": 1.789002537727356,
      "learning_rate": 3.055263157894737e-05,
      "loss": 2.7999,
      "step": 790
    },
    {
      "epoch": 0.41025641025641024,
      "grad_norm": 1.442768931388855,
      "learning_rate": 3.028947368421053e-05,
      "loss": 2.858,
      "step": 800
    },
    {
      "epoch": 0.41025641025641024,
      "eval_loss": 2.35026478767395,
      "eval_runtime": 2158.6605,
      "eval_samples_per_second": 3.613,
      "eval_steps_per_second": 3.613,
      "step": 800
    },
    {
      "epoch": 0.4153846153846154,
      "grad_norm": 2.8128037452697754,
      "learning_rate": 3.0026315789473686e-05,
      "loss": 2.7744,
      "step": 810
    },
    {
      "epoch": 0.4205128205128205,
      "grad_norm": 1.4506449699401855,
      "learning_rate": 2.9763157894736842e-05,
      "loss": 2.7898,
      "step": 820
    },
    {
      "epoch": 0.4256410256410256,
      "grad_norm": 1.565713882446289,
      "learning_rate": 2.95e-05,
      "loss": 2.7695,
      "step": 830
    },
    {
      "epoch": 0.4307692307692308,
      "grad_norm": 2.2076303958892822,
      "learning_rate": 2.9236842105263155e-05,
      "loss": 2.7319,
      "step": 840
    },
    {
      "epoch": 0.4358974358974359,
      "grad_norm": 1.9012954235076904,
      "learning_rate": 2.897368421052632e-05,
      "loss": 2.7556,
      "step": 850
    },
    {
      "epoch": 0.441025641025641,
      "grad_norm": 2.046483278274536,
      "learning_rate": 2.8710526315789475e-05,
      "loss": 2.7774,
      "step": 860
    },
    {
      "epoch": 0.4461538461538462,
      "grad_norm": 2.6640655994415283,
      "learning_rate": 2.8447368421052635e-05,
      "loss": 2.6964,
      "step": 870
    },
    {
      "epoch": 0.4512820512820513,
      "grad_norm": 1.5242714881896973,
      "learning_rate": 2.818421052631579e-05,
      "loss": 2.7501,
      "step": 880
    },
    {
      "epoch": 0.4564102564102564,
      "grad_norm": 2.158857822418213,
      "learning_rate": 2.7921052631578948e-05,
      "loss": 2.6895,
      "step": 890
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 1.819988489151001,
      "learning_rate": 2.7657894736842104e-05,
      "loss": 2.7257,
      "step": 900
    },
    {
      "epoch": 0.46153846153846156,
      "eval_loss": 2.276560068130493,
      "eval_runtime": 2177.4538,
      "eval_samples_per_second": 3.582,
      "eval_steps_per_second": 3.582,
      "step": 900
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 5.619330406188965,
      "learning_rate": 2.739473684210526e-05,
      "loss": 2.7338,
      "step": 910
    },
    {
      "epoch": 0.4717948717948718,
      "grad_norm": 2.4456679821014404,
      "learning_rate": 2.7131578947368424e-05,
      "loss": 2.6963,
      "step": 920
    },
    {
      "epoch": 0.47692307692307695,
      "grad_norm": 1.4917439222335815,
      "learning_rate": 2.686842105263158e-05,
      "loss": 2.6495,
      "step": 930
    },
    {
      "epoch": 0.48205128205128206,
      "grad_norm": 1.8109534978866577,
      "learning_rate": 2.6605263157894737e-05,
      "loss": 2.6323,
      "step": 940
    },
    {
      "epoch": 0.48717948717948717,
      "grad_norm": 1.577474594116211,
      "learning_rate": 2.6342105263157897e-05,
      "loss": 2.6902,
      "step": 950
    },
    {
      "epoch": 0.49230769230769234,
      "grad_norm": 1.719277262687683,
      "learning_rate": 2.6078947368421053e-05,
      "loss": 2.6399,
      "step": 960
    },
    {
      "epoch": 0.49743589743589745,
      "grad_norm": 2.4850847721099854,
      "learning_rate": 2.581578947368421e-05,
      "loss": 2.6323,
      "step": 970
    },
    {
      "epoch": 0.5025641025641026,
      "grad_norm": 1.5352717638015747,
      "learning_rate": 2.5552631578947366e-05,
      "loss": 2.6598,
      "step": 980
    },
    {
      "epoch": 0.5076923076923077,
      "grad_norm": 1.5830539464950562,
      "learning_rate": 2.528947368421053e-05,
      "loss": 2.6282,
      "step": 990
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 1.8257890939712524,
      "learning_rate": 2.5026315789473686e-05,
      "loss": 2.7152,
      "step": 1000
    },
    {
      "epoch": 0.5128205128205128,
      "eval_loss": 2.214334487915039,
      "eval_runtime": 2170.5149,
      "eval_samples_per_second": 3.594,
      "eval_steps_per_second": 3.594,
      "step": 1000
    },
    {
      "epoch": 0.517948717948718,
      "grad_norm": 1.5912214517593384,
      "learning_rate": 2.4763157894736843e-05,
      "loss": 2.6421,
      "step": 1010
    },
    {
      "epoch": 0.5230769230769231,
      "grad_norm": 1.7729634046554565,
      "learning_rate": 2.45e-05,
      "loss": 2.6114,
      "step": 1020
    },
    {
      "epoch": 0.5282051282051282,
      "grad_norm": 2.096904993057251,
      "learning_rate": 2.423684210526316e-05,
      "loss": 2.5812,
      "step": 1030
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 2.2974369525909424,
      "learning_rate": 2.397368421052632e-05,
      "loss": 2.5594,
      "step": 1040
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 2.682530641555786,
      "learning_rate": 2.3710526315789475e-05,
      "loss": 2.6551,
      "step": 1050
    },
    {
      "epoch": 0.5435897435897435,
      "grad_norm": 2.6092660427093506,
      "learning_rate": 2.3447368421052632e-05,
      "loss": 2.6085,
      "step": 1060
    },
    {
      "epoch": 0.5487179487179488,
      "grad_norm": 2.0486741065979004,
      "learning_rate": 2.3184210526315792e-05,
      "loss": 2.5551,
      "step": 1070
    },
    {
      "epoch": 0.5538461538461539,
      "grad_norm": 1.515579342842102,
      "learning_rate": 2.292105263157895e-05,
      "loss": 2.5353,
      "step": 1080
    },
    {
      "epoch": 0.558974358974359,
      "grad_norm": 1.7408846616744995,
      "learning_rate": 2.2657894736842105e-05,
      "loss": 2.5765,
      "step": 1090
    },
    {
      "epoch": 0.5641025641025641,
      "grad_norm": 2.412660598754883,
      "learning_rate": 2.2394736842105265e-05,
      "loss": 2.5465,
      "step": 1100
    },
    {
      "epoch": 0.5641025641025641,
      "eval_loss": 2.1641392707824707,
      "eval_runtime": 2195.4108,
      "eval_samples_per_second": 3.553,
      "eval_steps_per_second": 3.553,
      "step": 1100
    },
    {
      "epoch": 0.5692307692307692,
      "grad_norm": 1.4015023708343506,
      "learning_rate": 2.213157894736842e-05,
      "loss": 2.6069,
      "step": 1110
    },
    {
      "epoch": 0.5743589743589743,
      "grad_norm": 1.510541558265686,
      "learning_rate": 2.186842105263158e-05,
      "loss": 2.596,
      "step": 1120
    },
    {
      "epoch": 0.5794871794871795,
      "grad_norm": 1.565438151359558,
      "learning_rate": 2.1605263157894738e-05,
      "loss": 2.5758,
      "step": 1130
    },
    {
      "epoch": 0.5846153846153846,
      "grad_norm": 2.360607385635376,
      "learning_rate": 2.1342105263157897e-05,
      "loss": 2.5188,
      "step": 1140
    },
    {
      "epoch": 0.5897435897435898,
      "grad_norm": 1.7570956945419312,
      "learning_rate": 2.1078947368421054e-05,
      "loss": 2.5524,
      "step": 1150
    },
    {
      "epoch": 0.5948717948717949,
      "grad_norm": 1.5652244091033936,
      "learning_rate": 2.081578947368421e-05,
      "loss": 2.6416,
      "step": 1160
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9561398029327393,
      "learning_rate": 2.055263157894737e-05,
      "loss": 2.5078,
      "step": 1170
    },
    {
      "epoch": 0.6051282051282051,
      "grad_norm": 1.5971616506576538,
      "learning_rate": 2.0289473684210527e-05,
      "loss": 2.5359,
      "step": 1180
    },
    {
      "epoch": 0.6102564102564103,
      "grad_norm": 2.355438232421875,
      "learning_rate": 2.0026315789473683e-05,
      "loss": 2.4639,
      "step": 1190
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 1.743101716041565,
      "learning_rate": 1.9763157894736843e-05,
      "loss": 2.542,
      "step": 1200
    },
    {
      "epoch": 0.6153846153846154,
      "eval_loss": 2.120746612548828,
      "eval_runtime": 2207.6456,
      "eval_samples_per_second": 3.533,
      "eval_steps_per_second": 3.533,
      "step": 1200
    },
    {
      "epoch": 0.6205128205128205,
      "grad_norm": 1.6271913051605225,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 2.5031,
      "step": 1210
    },
    {
      "epoch": 0.6256410256410256,
      "grad_norm": 1.6620454788208008,
      "learning_rate": 1.923684210526316e-05,
      "loss": 2.5123,
      "step": 1220
    },
    {
      "epoch": 0.6307692307692307,
      "grad_norm": 1.4969786405563354,
      "learning_rate": 1.8973684210526316e-05,
      "loss": 2.522,
      "step": 1230
    },
    {
      "epoch": 0.6358974358974359,
      "grad_norm": 1.6013511419296265,
      "learning_rate": 1.8710526315789476e-05,
      "loss": 2.4752,
      "step": 1240
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 1.659645438194275,
      "learning_rate": 1.8447368421052632e-05,
      "loss": 2.5346,
      "step": 1250
    },
    {
      "epoch": 0.6461538461538462,
      "grad_norm": 1.9280362129211426,
      "learning_rate": 1.818421052631579e-05,
      "loss": 2.5187,
      "step": 1260
    },
    {
      "epoch": 0.6512820512820513,
      "grad_norm": 1.4834743738174438,
      "learning_rate": 1.792105263157895e-05,
      "loss": 2.4671,
      "step": 1270
    },
    {
      "epoch": 0.6564102564102564,
      "grad_norm": 1.3125717639923096,
      "learning_rate": 1.7657894736842105e-05,
      "loss": 2.495,
      "step": 1280
    },
    {
      "epoch": 0.6615384615384615,
      "grad_norm": 1.4332776069641113,
      "learning_rate": 1.7394736842105265e-05,
      "loss": 2.423,
      "step": 1290
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.463330626487732,
      "learning_rate": 1.713157894736842e-05,
      "loss": 2.4665,
      "step": 1300
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 2.093555212020874,
      "eval_runtime": 2078.0573,
      "eval_samples_per_second": 3.754,
      "eval_steps_per_second": 3.754,
      "step": 1300
    },
    {
      "epoch": 0.6717948717948717,
      "grad_norm": 1.727294683456421,
      "learning_rate": 1.686842105263158e-05,
      "loss": 2.4721,
      "step": 1310
    },
    {
      "epoch": 0.676923076923077,
      "grad_norm": 2.0920422077178955,
      "learning_rate": 1.6605263157894738e-05,
      "loss": 2.4873,
      "step": 1320
    },
    {
      "epoch": 0.6820512820512821,
      "grad_norm": 1.9818423986434937,
      "learning_rate": 1.6342105263157894e-05,
      "loss": 2.5306,
      "step": 1330
    },
    {
      "epoch": 0.6871794871794872,
      "grad_norm": 1.4563223123550415,
      "learning_rate": 1.6078947368421054e-05,
      "loss": 2.4611,
      "step": 1340
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 1.7729548215866089,
      "learning_rate": 1.581578947368421e-05,
      "loss": 2.4944,
      "step": 1350
    },
    {
      "epoch": 0.6974358974358974,
      "grad_norm": 1.6155990362167358,
      "learning_rate": 1.5552631578947367e-05,
      "loss": 2.4473,
      "step": 1360
    },
    {
      "epoch": 0.7025641025641025,
      "grad_norm": 1.5734353065490723,
      "learning_rate": 1.5289473684210527e-05,
      "loss": 2.5263,
      "step": 1370
    },
    {
      "epoch": 0.7076923076923077,
      "grad_norm": 1.4851254224777222,
      "learning_rate": 1.5026315789473685e-05,
      "loss": 2.454,
      "step": 1380
    },
    {
      "epoch": 0.7128205128205128,
      "grad_norm": 1.8477813005447388,
      "learning_rate": 1.4763157894736842e-05,
      "loss": 2.3876,
      "step": 1390
    },
    {
      "epoch": 0.717948717948718,
      "grad_norm": 2.661316394805908,
      "learning_rate": 1.45e-05,
      "loss": 2.4864,
      "step": 1400
    },
    {
      "epoch": 0.717948717948718,
      "eval_loss": 2.0638442039489746,
      "eval_runtime": 1897.1174,
      "eval_samples_per_second": 4.112,
      "eval_steps_per_second": 4.112,
      "step": 1400
    },
    {
      "epoch": 0.7230769230769231,
      "grad_norm": 1.4807732105255127,
      "learning_rate": 1.423684210526316e-05,
      "loss": 2.4309,
      "step": 1410
    },
    {
      "epoch": 0.7282051282051282,
      "grad_norm": 2.028689384460449,
      "learning_rate": 1.3973684210526316e-05,
      "loss": 2.474,
      "step": 1420
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 1.6790555715560913,
      "learning_rate": 1.3710526315789473e-05,
      "loss": 2.4155,
      "step": 1430
    },
    {
      "epoch": 0.7384615384615385,
      "grad_norm": 1.6410006284713745,
      "learning_rate": 1.3447368421052633e-05,
      "loss": 2.4212,
      "step": 1440
    },
    {
      "epoch": 0.7435897435897436,
      "grad_norm": 1.7343021631240845,
      "learning_rate": 1.3184210526315791e-05,
      "loss": 2.4821,
      "step": 1450
    },
    {
      "epoch": 0.7487179487179487,
      "grad_norm": 2.7489326000213623,
      "learning_rate": 1.2921052631578948e-05,
      "loss": 2.3984,
      "step": 1460
    },
    {
      "epoch": 0.7538461538461538,
      "grad_norm": 1.659454584121704,
      "learning_rate": 1.2657894736842104e-05,
      "loss": 2.435,
      "step": 1470
    },
    {
      "epoch": 0.7589743589743589,
      "grad_norm": 2.060620069503784,
      "learning_rate": 1.2394736842105264e-05,
      "loss": 2.4219,
      "step": 1480
    },
    {
      "epoch": 0.764102564102564,
      "grad_norm": 1.9880951642990112,
      "learning_rate": 1.2131578947368422e-05,
      "loss": 2.4142,
      "step": 1490
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.8713328838348389,
      "learning_rate": 1.186842105263158e-05,
      "loss": 2.4293,
      "step": 1500
    },
    {
      "epoch": 0.7692307692307693,
      "eval_loss": 2.042329788208008,
      "eval_runtime": 1901.2487,
      "eval_samples_per_second": 4.103,
      "eval_steps_per_second": 4.103,
      "step": 1500
    },
    {
      "epoch": 0.7743589743589744,
      "grad_norm": 1.4424203634262085,
      "learning_rate": 1.1605263157894737e-05,
      "loss": 2.3724,
      "step": 1510
    },
    {
      "epoch": 0.7794871794871795,
      "grad_norm": 3.4696290493011475,
      "learning_rate": 1.1342105263157895e-05,
      "loss": 2.4152,
      "step": 1520
    },
    {
      "epoch": 0.7846153846153846,
      "grad_norm": 1.547011137008667,
      "learning_rate": 1.1078947368421053e-05,
      "loss": 2.4273,
      "step": 1530
    },
    {
      "epoch": 0.7897435897435897,
      "grad_norm": 2.2390475273132324,
      "learning_rate": 1.0815789473684211e-05,
      "loss": 2.4089,
      "step": 1540
    },
    {
      "epoch": 0.7948717948717948,
      "grad_norm": 2.19260573387146,
      "learning_rate": 1.055263157894737e-05,
      "loss": 2.4104,
      "step": 1550
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8939579725265503,
      "learning_rate": 1.0289473684210526e-05,
      "loss": 2.4317,
      "step": 1560
    },
    {
      "epoch": 0.8051282051282052,
      "grad_norm": 1.7493687868118286,
      "learning_rate": 1.0026315789473686e-05,
      "loss": 2.3685,
      "step": 1570
    },
    {
      "epoch": 0.8102564102564103,
      "grad_norm": 1.9517184495925903,
      "learning_rate": 9.763157894736842e-06,
      "loss": 2.3963,
      "step": 1580
    },
    {
      "epoch": 0.8153846153846154,
      "grad_norm": 3.4002881050109863,
      "learning_rate": 9.5e-06,
      "loss": 2.4062,
      "step": 1590
    },
    {
      "epoch": 0.8205128205128205,
      "grad_norm": 1.4696381092071533,
      "learning_rate": 9.236842105263159e-06,
      "loss": 2.4064,
      "step": 1600
    },
    {
      "epoch": 0.8205128205128205,
      "eval_loss": 2.0246946811676025,
      "eval_runtime": 1892.8389,
      "eval_samples_per_second": 4.121,
      "eval_steps_per_second": 4.121,
      "step": 1600
    },
    {
      "epoch": 0.8256410256410256,
      "grad_norm": 2.150869131088257,
      "learning_rate": 8.973684210526317e-06,
      "loss": 2.4075,
      "step": 1610
    },
    {
      "epoch": 0.8307692307692308,
      "grad_norm": 1.8212246894836426,
      "learning_rate": 8.710526315789475e-06,
      "loss": 2.38,
      "step": 1620
    },
    {
      "epoch": 0.8358974358974359,
      "grad_norm": 1.5590418577194214,
      "learning_rate": 8.447368421052632e-06,
      "loss": 2.4513,
      "step": 1630
    },
    {
      "epoch": 0.841025641025641,
      "grad_norm": 1.8884174823760986,
      "learning_rate": 8.18421052631579e-06,
      "loss": 2.4014,
      "step": 1640
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 1.5399200916290283,
      "learning_rate": 7.921052631578948e-06,
      "loss": 2.4189,
      "step": 1650
    },
    {
      "epoch": 0.8512820512820513,
      "grad_norm": 1.6238306760787964,
      "learning_rate": 7.657894736842106e-06,
      "loss": 2.3727,
      "step": 1660
    },
    {
      "epoch": 0.8564102564102564,
      "grad_norm": 2.443589925765991,
      "learning_rate": 7.394736842105264e-06,
      "loss": 2.2953,
      "step": 1670
    },
    {
      "epoch": 0.8615384615384616,
      "grad_norm": 2.6812849044799805,
      "learning_rate": 7.131578947368421e-06,
      "loss": 2.3301,
      "step": 1680
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 1.5085852146148682,
      "learning_rate": 6.86842105263158e-06,
      "loss": 2.3846,
      "step": 1690
    },
    {
      "epoch": 0.8717948717948718,
      "grad_norm": 1.669805645942688,
      "learning_rate": 6.605263157894736e-06,
      "loss": 2.3914,
      "step": 1700
    },
    {
      "epoch": 0.8717948717948718,
      "eval_loss": 2.0165843963623047,
      "eval_runtime": 1919.5276,
      "eval_samples_per_second": 4.063,
      "eval_steps_per_second": 4.063,
      "step": 1700
    },
    {
      "epoch": 0.8769230769230769,
      "grad_norm": 1.7160815000534058,
      "learning_rate": 6.342105263157895e-06,
      "loss": 2.3989,
      "step": 1710
    },
    {
      "epoch": 0.882051282051282,
      "grad_norm": 2.1869940757751465,
      "learning_rate": 6.078947368421053e-06,
      "loss": 2.3992,
      "step": 1720
    },
    {
      "epoch": 0.8871794871794871,
      "grad_norm": 1.490470051765442,
      "learning_rate": 5.815789473684211e-06,
      "loss": 2.2892,
      "step": 1730
    },
    {
      "epoch": 0.8923076923076924,
      "grad_norm": 1.9893441200256348,
      "learning_rate": 5.552631578947369e-06,
      "loss": 2.3836,
      "step": 1740
    },
    {
      "epoch": 0.8974358974358975,
      "grad_norm": 1.5157372951507568,
      "learning_rate": 5.289473684210526e-06,
      "loss": 2.373,
      "step": 1750
    },
    {
      "epoch": 0.9025641025641026,
      "grad_norm": 1.5940912961959839,
      "learning_rate": 5.026315789473685e-06,
      "loss": 2.3369,
      "step": 1760
    },
    {
      "epoch": 0.9076923076923077,
      "grad_norm": 1.434677004814148,
      "learning_rate": 4.763157894736842e-06,
      "loss": 2.4041,
      "step": 1770
    },
    {
      "epoch": 0.9128205128205128,
      "grad_norm": 1.955463171005249,
      "learning_rate": 4.5e-06,
      "loss": 2.3687,
      "step": 1780
    },
    {
      "epoch": 0.9179487179487179,
      "grad_norm": 1.5196335315704346,
      "learning_rate": 4.2368421052631575e-06,
      "loss": 2.366,
      "step": 1790
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 1.6146060228347778,
      "learning_rate": 3.9736842105263165e-06,
      "loss": 2.3795,
      "step": 1800
    },
    {
      "epoch": 0.9230769230769231,
      "eval_loss": 2.0070605278015137,
      "eval_runtime": 1900.9162,
      "eval_samples_per_second": 4.103,
      "eval_steps_per_second": 4.103,
      "step": 1800
    },
    {
      "epoch": 0.9282051282051282,
      "grad_norm": 1.7313909530639648,
      "learning_rate": 3.710526315789474e-06,
      "loss": 2.3349,
      "step": 1810
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.6913374662399292,
      "learning_rate": 3.4473684210526316e-06,
      "loss": 2.3525,
      "step": 1820
    },
    {
      "epoch": 0.9384615384615385,
      "grad_norm": 1.60275137424469,
      "learning_rate": 3.1842105263157893e-06,
      "loss": 2.3594,
      "step": 1830
    },
    {
      "epoch": 0.9435897435897436,
      "grad_norm": 2.700855016708374,
      "learning_rate": 2.9210526315789475e-06,
      "loss": 2.3558,
      "step": 1840
    },
    {
      "epoch": 0.9487179487179487,
      "grad_norm": 1.8605812788009644,
      "learning_rate": 2.6578947368421053e-06,
      "loss": 2.4177,
      "step": 1850
    },
    {
      "epoch": 0.9538461538461539,
      "grad_norm": 1.921291708946228,
      "learning_rate": 2.394736842105263e-06,
      "loss": 2.3429,
      "step": 1860
    },
    {
      "epoch": 0.958974358974359,
      "grad_norm": 1.5010812282562256,
      "learning_rate": 2.1315789473684212e-06,
      "loss": 2.3731,
      "step": 1870
    },
    {
      "epoch": 0.9641025641025641,
      "grad_norm": 1.748065710067749,
      "learning_rate": 1.868421052631579e-06,
      "loss": 2.3001,
      "step": 1880
    },
    {
      "epoch": 0.9692307692307692,
      "grad_norm": 2.2842111587524414,
      "learning_rate": 1.6052631578947368e-06,
      "loss": 2.3533,
      "step": 1890
    },
    {
      "epoch": 0.9743589743589743,
      "grad_norm": 1.581602931022644,
      "learning_rate": 1.342105263157895e-06,
      "loss": 2.3694,
      "step": 1900
    },
    {
      "epoch": 0.9743589743589743,
      "eval_loss": 2.0073049068450928,
      "eval_runtime": 1878.1585,
      "eval_samples_per_second": 4.153,
      "eval_steps_per_second": 4.153,
      "step": 1900
    },
    {
      "epoch": 0.9794871794871794,
      "grad_norm": 2.191840648651123,
      "learning_rate": 1.0789473684210527e-06,
      "loss": 2.3924,
      "step": 1910
    },
    {
      "epoch": 0.9846153846153847,
      "grad_norm": 1.56121027469635,
      "learning_rate": 8.157894736842106e-07,
      "loss": 2.3801,
      "step": 1920
    },
    {
      "epoch": 0.9897435897435898,
      "grad_norm": 1.5723850727081299,
      "learning_rate": 5.526315789473684e-07,
      "loss": 2.3559,
      "step": 1930
    },
    {
      "epoch": 0.9948717948717949,
      "grad_norm": 1.5956629514694214,
      "learning_rate": 2.8947368421052637e-07,
      "loss": 2.3722,
      "step": 1940
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8151068687438965,
      "learning_rate": 2.631578947368421e-08,
      "loss": 2.3591,
      "step": 1950
    }
  ],
  "logging_steps": 10,
  "max_steps": 1950,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2041611131289600.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
