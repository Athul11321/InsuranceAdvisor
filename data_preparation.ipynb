{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cfe6ca3-d852-44ad-9f5f-8709c0e5700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets transformers torch pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e1e543-3586-4bc3-9dd4-f5ef1bc6a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d264a749-0c6a-495b-a91b-8eada1f54627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'intent', 'category', 'tags', 'response'],\n",
      "        num_rows: 39000\n",
      "    })\n",
      "})\n",
      "Number of examples: 39000\n",
      "First example: {'instruction': \"I'd like to see my fucking auto insurance , I need assistance\", 'intent': 'information_auto_insurance', 'category': 'AUTO_INSURANCE', 'tags': 'BCLPWZ', 'response': 'To retrieve the details of your auto insurance, please adhere to the following instructions:\\n\\n1. Access your account by navigating to {{WEBSITE_URL}}.\\n2. Proceed to the {{MY_POLICIES_SECTION}} section within your profile.\\n3. Select the auto insurance policy that you want to review.\\n\\nThis process will grant you comprehensive access to your auto insurance information. Should you require any additional support, do not hesitate to contact me.'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"bitext/Bitext-insurance-llm-chatbot-training-dataset\")\n",
    "print(f\"Dataset structure: {dataset}\")\n",
    "print(f\"Number of examples: {len(dataset['train'])}\")\n",
    "print(f\"First example: {dataset['train'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ddcba4c-eb85-4fb9-af28-7b116c985b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['instruction', 'intent', 'category', 'tags', 'response']\n",
      "Dataset shape: (39000, 5)\n",
      "\n",
      "First 5 rows:\n",
      "                                         instruction  \\\n",
      "0  I'd like to see my fucking auto insurance , I ...   \n",
      "1  wanna know more about my auto insurance giev m...   \n",
      "2  I'd like to sde my fucking auto insurance coul...   \n",
      "3  wanna see my fucking auto insurance where coul...   \n",
      "4  I need information about my fucking auto insur...   \n",
      "\n",
      "                       intent        category      tags  \\\n",
      "0  information_auto_insurance  AUTO_INSURANCE    BCLPWZ   \n",
      "1  information_auto_insurance  AUTO_INSURANCE      BCQZ   \n",
      "2  information_auto_insurance  AUTO_INSURANCE  BCILPQWZ   \n",
      "3  information_auto_insurance  AUTO_INSURANCE   BCILPQW   \n",
      "4  information_auto_insurance  AUTO_INSURANCE      BCIW   \n",
      "\n",
      "                                            response  \n",
      "0  To retrieve the details of your auto insurance...  \n",
      "1  To retrieve your auto insurance details, pleas...  \n",
      "2  To obtain your auto insurance information, kin...  \n",
      "3  To retrieve your auto insurance details, pleas...  \n",
      "4  To retrieve your auto insurance details, pleas...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8b4a416-e211-4b37-ac0f-c86956983e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent distribution:\n",
      "intent\n",
      "information_auto_insurance       1000\n",
      "accept_settlement                1000\n",
      "file_claim                       1000\n",
      "negotiate_settlement             1000\n",
      "receive_payment                  1000\n",
      "reject_settlement                1000\n",
      "track_claim                      1000\n",
      "appeal_denied_insurance_claim    1000\n",
      "dispute_invoice                  1000\n",
      "file_complaint                   1000\n",
      "agent                            1000\n",
      "customer_service                 1000\n",
      "human_agent                      1000\n",
      "insurance_representative         1000\n",
      "change_coverage                  1000\n",
      "check_coverage                   1000\n",
      "downgrade_coverage               1000\n",
      "upgrade_coverage                 1000\n",
      "buy_insurance_policy             1000\n",
      "cancellation_fees                1000\n",
      "cancel_insurance_policy          1000\n",
      "compare_insurance_policies       1000\n",
      "general_information              1000\n",
      "information_health_insurance     1000\n",
      "information_home_insurance       1000\n",
      "report_incident                  1000\n",
      "schedule_appointment             1000\n",
      "information_life_insurance       1000\n",
      "check_payments                   1000\n",
      "payment_methods                  1000\n",
      "pay                              1000\n",
      "report_payment_issue             1000\n",
      "schedule_payments                1000\n",
      "information_pet_insurance        1000\n",
      "change_personal_details          1000\n",
      "calculate_insurance_quote        1000\n",
      "check_rates                      1000\n",
      "renew_insurance_policy           1000\n",
      "information_travel_insurance     1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "intent_counts = df['intent'].value_counts()\n",
    "print(f\"Intent distribution:\\n{intent_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b936dc1-faf0-43c7-8b6d-d839f5e0824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_intents = [\n",
    "    'check_coverage', 'policy_details', 'insurance_types', \n",
    "    'deductible_info', 'coverage_limits', 'exclusions'\n",
    "]\n",
    "\n",
    "claims_intents = [\n",
    "    'file_claim', 'claim_status', 'claim_documentation', \n",
    "    'claim_process', 'claim_timeline'\n",
    "]\n",
    "\n",
    "premium_intents = [\n",
    "    'get_quote', 'premium_factors', 'discount_eligibility', \n",
    "    'payment_options', 'premium_calculation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93dff1e8-7bfd-468b-95cb-d8e426fdb606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category distribution:\n",
      "category\n",
      "OTHER     37000\n",
      "CLAIMS     1000\n",
      "FAQ        1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def categorize_intent(intent):\n",
    "    if intent in faq_intents:\n",
    "        return 'FAQ'\n",
    "    elif intent in claims_intents:\n",
    "        return 'CLAIMS'\n",
    "    elif intent in premium_intents:\n",
    "        return 'PREMIUM'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "df['category'] = df['intent'].apply(categorize_intent)\n",
    "print(f\"Category distribution:\\n{df['category'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7de675-16fb-4b77-8152-a1b53bdaa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    # Create instruction-response pairs\n",
    "    example = {\n",
    "        'instruction': row['instruction'],\n",
    "        'response': row['response'],\n",
    "        'intent': row['intent'],\n",
    "        'category': row['category']\n",
    "    }\n",
    "    training_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b0486a9-daeb-41ca-aa3f-d1e6888baf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 31200\n",
      "Validation examples: 7800\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(\n",
    "    training_examples, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=[ex['category'] for ex in training_examples]\n",
    ")\n",
    "\n",
    "print(f\"Training examples: {len(train_data)}\")\n",
    "print(f\"Validation examples: {len(val_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52856901-8275-4a40-8546-7c9321303246",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.json', 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "with open('val_data.json', 'w') as f:\n",
    "    json.dump(val_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702a211-573d-4503-81b3-471a9ae99361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
