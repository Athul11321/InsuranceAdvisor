# ğŸ›¡ï¸ Insurance Advisor Chatbot

An intelligent, locally hosted chatbot for providing insurance-related assistance to users. This project leverages a local LLM (Language Model), with a Flask backend and a clean HTML/CSS/JS-based frontend. It aims to automate insurance query handling and improve customer experience in the insurance domain.

---

## ğŸš€ Features

- Conversational interface for insurance queries
- Trained on domain-specific data (insurance dataset)
- Flask-based backend with LLM integration
- Interactive frontend using HTML/CSS/JavaScript
- Evaluation and performance reporting
- Modular design for easy enhancements

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: HTML, CSS, JavaScript
- **Backend**: Python (Flask)
- **LLM**: Local model integrated via Python (DialoGPT-small + LoRA/PEFT)
- **Data**: Custom CSV-based insurance dataset
- **Tools**: Jupyter Notebook, Pandas, Scikit-learn, HuggingFace Transformers, Datasets

---

## ğŸ“ Project Structure

```
InsuranceAdvisor/
â”‚
â”œâ”€â”€ app.py                      # Flask app to run the backend
â”œâ”€â”€ config.json                 # Configuration for model paths and settings
â”œâ”€â”€ insurance_data.csv          # Dataset used for training/evaluation
â”œâ”€â”€ data_preparation.ipynb      # Jupyter notebook for preprocessing data
â”œâ”€â”€ model_training.ipynb        # Notebook for model training (LoRA/PEFT)
â”œâ”€â”€ model_testing.ipynb         # Notebook for model testing and analysis
â”œâ”€â”€ evaluate_model.ipynb        # Evaluation workflow
â”œâ”€â”€ evaluation_report.md        # Performance insights and accuracy details
â”œâ”€â”€ evaluation_summary.json     # Summary of evaluation metrics
â”œâ”€â”€ model_evaluation_results.csv# Detailed evaluation results
â”œâ”€â”€ train_data.json             # Training data (JSON)
â”œâ”€â”€ val_data.json               # Validation data (JSON)
â”œâ”€â”€ static/                     # CSS and JS files
â”œâ”€â”€ templates/                  # HTML templates for frontend
â”œâ”€â”€ insurance-chatbot-cpu/      # Saved model and tokenizer
â”œâ”€â”€ insurance-chatbot-model-cpu/# Model checkpoints
â””â”€â”€ .gitignore, .gitattributes  # Git metadata
```

---

## ğŸ§  Model & Dataset

- The chatbot is trained on `insurance_data.csv` with intent classification and domain-specific Q&A patterns.
- Data preparation and evaluation workflows are provided in Jupyter notebooks:
  - [`data_preparation.ipynb`](data_preparation.ipynb)
  - [`evaluate_model.ipynb`](evaluate_model.ipynb)
- Model training uses HuggingFace Transformers with LoRA/PEFT for efficient fine-tuning on CPU.

---

## ğŸ“Š Evaluation

Performance analysis of the chatbot is documented in:
- [`evaluation_report.md`](evaluation_report.md)
- [`evaluation_summary.json`](evaluation_summary.json)

---

## âš¡ Quickstart

1. **Install dependencies**  
   ```
   pip install -r requirements.txt
   ```

2. **Prepare data**  
   Run `data_preparation.ipynb` to generate `train_data.json` and `val_data.json`.

3. **Train the model**  
   Run `model_training.ipynb` to fine-tune the chatbot model.

4. **Evaluate the model**  
   Run `model_testing.ipynb` or `evaluate_model.ipynb` for performance metrics.

5. **Start the server**  
   ```
   python app.py
   ```
   Visit [http://localhost:5000](http://localhost:5000) in your browser.


---

## ğŸ™ Acknowledgements

- [HuggingFace Transformers](https://github.com/huggingface/transformers)
- [PEFT/LoRA](https://github.com/huggingface/peft)
- [Pandas](https://pandas.pydata.org/)
- [Scikit-learn](https://scikit-learn.org/)


